{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Utils.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyP+UK229rCTxyNxPmG2i5QE"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"DT_uEptxIRC_"},"source":["import numpy as np\n","\n","import os\n","import copy\n","\n","import pandas as pd\n","\n","# import IPython.display as ipd # to listen to the files\n","import librosa # to manipulate audiofiles, audio preprocessing ==> need to read more https://librosa.org/doc/latest/index.html\n","# import python_speech_features as psf # some filtering and stuff ==> need to read more https://python-speech-features.readthedocs.io/en/latest/\n","# pyAudioAnalysis looks like a good library for feature extraction: https://github.com/tyiannak/pyAudioAnalysis ==> try?\n","import librosa.display\n","\n","from matplotlib import pyplot as plt\n","\n","import scipy"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"HK6XswlzIYSU"},"source":["def get_mfcc(full_audio_path):\n","    '''\n","    https://stackoverflow.com/questions/37963042/python-librosa-what-is-the-default-frame-size-used-to-compute-the-mfcc-feature\n","    \n","    https://medium.com/@jonathan_hui/speech-recognition-feature-extraction-mfcc-plp-5455f5a69dd9#:~:text=PLP%20is%20very%20similar%20to,instead%20of%20the%20log%20compression.&text=It%20also%20uses%20linear%20regressive,and%20slightly%20better%20noise%20robustness.\n","    '''\n","    #audio_length_seconds = 2.5\n","    sample_rate = 44100\n","    hop_size = 512#347*audio_length_seconds\n","    fmin = 20\n","    fmax = sample_rate // 2\n","    n_mels = 128\n","    n_fft = n_mels * 20\n","    #samples = sample_rate * audio_length_seconds\n","\n","    wave, __ =  librosa.load(full_audio_path)\n","    #clip on fix length\n","    wave = librosa.util.fix_length(wave, 132300, mode='constant')\n","    \n","    mfcc_features = librosa.feature.mfcc(y=wave, sr=sample_rate, n_mfcc =39,hop_length=int(hop_size),n_fft=n_fft,fmin=fmin,fmax=fmax)#n_mels=n_mels,\n","    #normalize\n","    mfcc_features -= (np.mean(mfcc_features, axis=0) + 1e-8)\n","    \n","    \n","    return mfcc_features"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Iraz3JPCSdda"},"source":["def load_pickle(path):\n","    return pd.read_pickle(path)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"tuwP7qN5IZKf"},"source":["def add_noise(signal):\n","    noise = np.random.normal(0, 0.01, len(signal))\n","    noisy_signal = signal + noise\n","    #ipd.Audio(noisy_signal, rate=sample_rate)\n","    return noisy_signal"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"bPiXOw1JIzw-"},"source":["def change_pitch(signal,sample_rate):\n","    # Change pitch\n","\n","    # Define how many fractional half steps it should be shifted\n","    n_steps = 4\n","    pitch_shifted = librosa.effects.pitch_shift(signal, sample_rate, n_steps)\n","    #ipd.Audio(pitch_shifted, rate=sample_rate)\n","    return pitch_shifted\n","\n","def time_stretch(signal):\n","    # Time stretch\n","    stretch_factor = 0.7\n","    time_stretched = librosa.effects.time_stretch(signal, stretch_factor)\n","    #ipd.Audio(time_stretched, rate=sample_rate)\n","    return time_stretched"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"73u2wIu3Jz_4"},"source":["def filter_signal(signal):\n","    # Filter a \"bad\" noisy sample to see what the filter does\n","\n","    # Apply Wiener filter. Documentation said window length should be uneven, although I don't understand why.\n","    filter_window_length = 7\n","    filtered_signal = scipy.signal.wiener(signal, mysize=filter_window_length)\n","    return filtered_signal"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"YTyaDqWpKWlg"},"source":["def filter_low_energy_signal(signal,threshold):\n","    energy = np.sum(librosa.feature.rmse(signal))\n","  \n","    if energy < threshold:\n","        return True"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"vDeAdvgMKIM7"},"source":["#Function to randomly mask out a stretch of time\n","def mask_time(spectrogram, max_masked=25, n_masks=1):\n","\n","  x, y = spectrogram.shape\n","  altered_spec = copy.deepcopy(spectrogram)\n","\n","  for i in range(n_masks):\n","    mask_size = np.random.randint(low=0, high=max_masked+1)\n","    mask_point = np.random.randint(low=0, high=y-mask_size)\n","    altered_spec[:, mask_point:mask_point+mask_size] = 0\n","\n","  return altered_spec\n","\n","# Function to randomly mask out a stretch of frequencies\n","def mask_freq(spectrogram, max_masked=25, n_masks=1):\n","\n","  x, y = spectrogram.shape\n","  altered_spec = copy.deepcopy(spectrogram)\n","\n","  for i in range(n_masks):\n","    mask_size = np.random.randint(low=0, high=max_masked+1)\n","    mask_point = np.random.randint(low=0, high=x-mask_size)\n","    altered_spec[mask_point:mask_point+mask_size, :] = 0\n","\n","  return altered_spec\n","\n","# Function to randomly mask out time and frequency stretches\n","def mask_both(spectrogram, max_masked_time, n_time, max_masked_freq, n_freq):\n","\n","  spec = copy.deepcopy(spectrogram)\n","\n","  spec = mask_time(spec, max_masked_time, n_time)\n","  spec = mask_freq(spec, max_masked_freq, n_freq)\n","\n","  return spec"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"qCJvp8tQzGFw"},"source":["#create a dictionary with key as label and features as values\n","def createFilepathDic(dfrow,datadic,wd):\n","    #print file path\n","    #print(dfrow[0])\n","    path = os.path.join(wd,dfrow[0])\n","    label = dfrow[1]\n","    #feature = get_mfcc(path)\n","    #print(feature.shape)\n","    if label not in datadic.keys():\n","      datadic[label] = []\n","      datadic[label].append(path)\n","    else:\n","      exist_path = datadic[label]\n","      exist_path.append(path)\n","      datadic[label] = exist_path\n","\n","    return datadic"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"7_M0Jgxg2D46"},"source":["#in the existing dictionary add new files\n","def add_to_DataDic(datadic,newfile,wd):\n","    print(os.listdir(os.path.join(wd,newfile)))\n","    for label in os.listdir(os.path.join(wd,newfile)):\n","        print(label)\n","        if label not in datadic.keys():\n","            datadic[label] = []\n","            path = newfile + label\n","            for file in os.listdir(os.path.join(wd,path)):\n","                filepath = os.path.join(os.path.join(wd,path),file)\n","                \n","                datadic[label].append(filepath)\n","        else:\n","            path = newfile + label\n","            for file in os.listdir(os.path.join(wd,path)):\n","                \n","                filepath = os.path.join(os.path.join(wd,path),file)\n","                \n","                \n","                exist_file = datadic[label]\n","                exist_file.append(filepath)\n","                datadic[label] = exist_file\n","\n","    return datadic"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ZhPpoYXY-2pp"},"source":["class GetFeatureDic():\n","  \n","    def __init__(self,extractor):\n","        self.extractor = extractor\n","        \n","    #create a dictionary with key as label and features as values\n","    def createFeatureDic(self,datadic):\n","        featuredic = {}\n","        for label in datadic.keys():\n","            featuredic[label] = [ self.extractor(path) for path in datadic[label]]  \n","        return featuredic"],"execution_count":null,"outputs":[]}]}